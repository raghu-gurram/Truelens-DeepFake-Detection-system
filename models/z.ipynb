{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the fine-tuned Xception model\n",
    "model = tf.keras.models.load_model('xception_model.h5')\n",
    "\n",
    "# Function to predict whether an input image is real or fake and return the real %\n",
    "def predict_real_fake(image_path):\n",
    "    # Preprocess the image\n",
    "    img_array, original_image = preprocess_image(image_path)\n",
    "    predictions = model.predict(img_array)\n",
    "    real_prob = predictions[0][0]\n",
    "    return real_prob * 100  # Return percentage for real\n",
    "\n",
    "# Function to generate a heatmap for an input image using Grad-CAM\n",
    "def generate_heatmap(image_path, layer_name='block14_sepconv2'):\n",
    "    img_array, original_image = preprocess_image(image_path)\n",
    "    heatmap = grad_cam(model, img_array, layer_name)\n",
    "    overlayed_image = overlay_heatmap(heatmap, np.uint8(original_image))\n",
    "    return overlayed_image, heatmap\n",
    "\n",
    "# Function to plot the graph of real % for each frame in a video\n",
    "def plot_frame_real_predictions(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_real_probs = []\n",
    "    frame_count = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert frame to RGB and preprocess\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        img_array = preprocess_image_from_array(frame_rgb)\n",
    "\n",
    "        # Predict real probability for the frame\n",
    "        predictions = model.predict(img_array)\n",
    "        real_prob = predictions[0][0]\n",
    "\n",
    "        frame_real_probs.append(real_prob * 100)\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # Plotting the graph\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(range(1, frame_count + 1), frame_real_probs, label='Real % Prediction')\n",
    "    plt.xlabel('Frame Number')\n",
    "    plt.ylabel('Real %')\n",
    "    plt.title('Real % Prediction Over Video Frames')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Helper function to preprocess the image\n",
    "def preprocess_image(image_path, target_size=(299, 299)):\n",
    "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=target_size)\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = tf.keras.applications.xception.preprocess_input(img_array)\n",
    "    return img_array, img\n",
    "\n",
    "# Helper function to preprocess the image from an array (used for video frames)\n",
    "def preprocess_image_from_array(image_array, target_size=(299, 299)):\n",
    "    img_array = cv2.resize(image_array, target_size)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = tf.keras.applications.xception.preprocess_input(img_array)\n",
    "    return img_array\n",
    "\n",
    "# Grad-CAM implementation\n",
    "def grad_cam(model, img_array, layer_name, pred_index=None):\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs],\n",
    "        [model.get_layer(layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(predictions[0])\n",
    "        loss = predictions[:, pred_index]\n",
    "\n",
    "    grads = tape.gradient(loss, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # Normalize heatmap\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "# Overlay heatmap on the image\n",
    "def overlay_heatmap(heatmap, image, alpha=0.4, colormap=cv2.COLORMAP_JET):\n",
    "    heatmap = cv2.resize(heatmap, (image.shape[1], image.shape[0]))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, colormap)\n",
    "    overlayed_img = cv2.addWeighted(heatmap, alpha, image, 1 - alpha, 0)\n",
    "    return overlayed_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 921ms/step\n",
      "Predicted real % for img1.png: 0.15%\n"
     ]
    }
   ],
   "source": [
    "# Predict real % for img1.png\n",
    "real_prob_img1 = predict_real_fake('img4.png')\n",
    "print(f\"Predicted real % for img1.png: {real_prob_img1:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the pre-trained deepfake detection model (replace this with your model if available)\n",
    "# This example uses Xception with ImageNet weights for demonstration purposes.\n",
    "# Replace with your actual deepfake detection model.\n",
    "model = tf.keras.models.load_model('xception_model.h5')\n",
    "# model = tf.keras.applications.Xception(weights='imagenet')\n",
    "\n",
    "# Load the face detection model from OpenCV\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Function to preprocess image for prediction\n",
    "def preprocess_image(image, target_size=(299, 299)):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, target_size)\n",
    "    image = image / 255.0  # Normalize pixel values\n",
    "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "    return image\n",
    "\n",
    "# Function to draw a box with the prediction\n",
    "def draw_prediction(image, x, y, w, h, prediction):\n",
    "    if prediction < 0.5:\n",
    "        # Red box for low confidence (below 50%)\n",
    "        color = (0, 0, 255)\n",
    "        label = f\"Real: {100 * (1 - prediction):.2f}%\"\n",
    "    else:\n",
    "        # Green box for high confidence (above 50%)\n",
    "        color = (0, 255, 0)\n",
    "        label = f\"Fake: {100 * prediction:.2f}%\"\n",
    "    \n",
    "    # Draw the rectangle around the face\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
    "    \n",
    "    # Put the label on the box\n",
    "    cv2.putText(image, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "\n",
    "# Function to detect and predict deepfake status for faces in the image\n",
    "def detect_and_predict(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the image\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Crop and preprocess the face for prediction\n",
    "        face_img = image[y:y+h, x:x+w]\n",
    "        face_array = preprocess_image(face_img)\n",
    "\n",
    "        # Predict using the pre-trained model\n",
    "        prediction = model.predict(face_array)[0][0]  # Adjust indexing based on the model output format\n",
    "\n",
    "        # Draw the prediction on the image\n",
    "        draw_prediction(image, x, y, w, h, prediction)\n",
    "\n",
    "    # Display the image with the boxes and predictions\n",
    "    cv2.imshow('Face Detection and Deepfake Prediction', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    image_path = 'img1.png'  # Replace with your image path\n",
    "    detect_and_predict(image_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
